# ================================================
# SOCIAL MEDIA SENTIMENT ANALYZER - CONFIGURATION
# ================================================

# ----------------
# Reddit API
# ----------------
# Obtenir les clés: https://www.reddit.com/prefs/apps
REDDIT_CLIENT_ID=your_reddit_client_id_here
REDDIT_CLIENT_SECRET=your_reddit_client_secret_here
REDDIT_USER_AGENT=SocialMediaAnalyzer/1.0

# ----------------
# Twitter API v2
# ----------------
# Obtenir les clés: https://developer.twitter.com/en/portal/dashboard
TWITTER_BEARER_TOKEN=your_twitter_bearer_token_here
TWITTER_API_KEY=your_twitter_api_key_here
TWITTER_API_SECRET=your_twitter_api_secret_here
TWITTER_ACCESS_TOKEN=your_twitter_access_token_here
TWITTER_ACCESS_TOKEN_SECRET=your_twitter_access_token_secret_here

# ----------------
# Database
# ----------------
# PostgreSQL connection URL
# Format: postgresql+asyncpg://user:password@host:port/database
# Docker: postgresql+asyncpg://postgres:postgres@postgresql:5432/social_media_analyzer
# Local: postgresql+asyncpg://postgres:postgres@localhost:5432/social_media_analyzer
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/social_media_analyzer

# ----------------
# Cache (Optional)
# ----------------
# Redis URL for caching
REDIS_URL=redis://localhost:6379

# ----------------
# Application
# ----------------
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True

# ----------------
# Deep Learning Models
# ----------------
# Hugging Face model names or local paths
SENTIMENT_MODEL=cardiffnlp/twitter-roberta-base-sentiment-latest
SUMMARIZATION_MODEL=facebook/bart-large-cnn

# Use custom fine-tuned model (after training):
# SENTIMENT_MODEL=./models/custom-roberta-sentiment

# ----------------
# LLM Configuration (Groq)
# ----------------
# Get your FREE API key from: https://console.groq.com
# Ultra-fast inference with open-source models
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Available Groq models:
# - llama-3.3-70b-versatile (⭐ recommended - fast, versatile)
# - llama-3.1-70b-versatile (stable alternative)
# - mixtral-8x7b-32768 (long context - 32k tokens)
# - gemma2-9b-it (lightweight and fast)

# ----------------
# Performance & Limits
# ----------------
# Maximum posts per search request (1-50)
MAX_POSTS_PER_REQUEST=30

# Maximum comments per post to analyze
MAX_COMMENTS_PER_POST=10

# Maximum posts to fetch per platform for trends analysis
MAX_TRENDS_FETCH_PER_PLATFORM=1500

# Review filtering multiplier (fetch N times more posts to filter)
REVIEW_OVERFETCH_FACTOR=5

# ----------------
# Advanced Settings
# ----------------
# Enable/disable features
ENABLE_COMMENT_SUMMARIZATION=True
ENABLE_TRENDS_IN_SEARCH=False

# Pagination settings for trends
ENABLE_TRENDS_PAGINATION=True
REDDIT_PAGINATION_BATCH_SIZE=100
TWITTER_PAGINATION_BATCH_SIZE=100
TRENDS_MAX_API_CALLS=15
