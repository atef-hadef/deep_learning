# ğŸ¤– Analyseur de Sentiments Multi-Plateformes avec IA

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.6+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> SystÃ¨me intelligent d'analyse de sentiments en temps rÃ©el sur les rÃ©seaux sociaux (Reddit et Twitter) utilisant des modÃ¨les de Deep Learning avancÃ©s et gÃ©nÃ©ration de rÃ©sumÃ©s avec LLM.

## ğŸ¯ FonctionnalitÃ©s Principales

### ğŸ” Collecte Intelligente de DonnÃ©es
- **Multi-plateformes** : Reddit et Twitter avec support simultanÃ©
- **Filtrage intelligent** : DÃ©tection automatique des avis/reviews avec OpinionDetector (CNN)
- **Fetching adaptatif** : SystÃ¨me de pagination intelligent pour obtenir exactement le nombre d'avis souhaitÃ©s
- **Collecte profonde** : Posts + commentaires avec limite configurable

### ğŸ§  Analyse IA AvancÃ©e
- **Analyse de sentiments** : Classification prÃ©cise (positif/nÃ©gatif/neutre) avec RoBERTa fine-tunÃ©
- **RÃ©sumÃ©s LLM** : GÃ©nÃ©ration de rÃ©sumÃ©s intelligents avec Grok/Claude via OpenRouter API
- **Extraction d'aspects** : Identification automatique des caractÃ©ristiques mentionnÃ©es
- **DÃ©tection d'opinions** : ModÃ¨le CNN custom pour filtrer les avis pertinents

### ğŸ“Š Visualisation et Tendances
- **Analyse temporelle** : Ã‰volution des mentions et sentiments sur 7-30 jours
- **Graphiques interactifs** : Chart.js avec animations fluides
- **Comparaison multi-plateformes** : Vue unifiÃ©e Reddit vs Twitter
- **Dashboard temps rÃ©el** : Statistiques agrÃ©gÃ©es et insights

### ğŸ’¾ Infrastructure Robuste
- **Base de donnÃ©es** : PostgreSQL avec fallback cache mÃ©moire
- **API REST complÃ¨te** : Documentation Swagger/OpenAPI automatique
- **DÃ©ploiement Docker** : Configuration prÃªte pour production
- **Performance optimisÃ©e** : Traitement asynchrone et batch processing

## ğŸ“‹ Table des MatiÃ¨res

- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ’» Technologies](#-technologies)
- [ğŸš€ Installation Rapide](#-installation-rapide)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸ“– Guide d'Utilisation](#-guide-dutilisation)
- [ğŸ³ DÃ©ploiement Docker](#-dÃ©ploiement-docker)
- [ğŸ“š Documentation API](#-documentation-api)
- [ğŸ“ Fine-tuning des ModÃ¨les](#-fine-tuning-des-modÃ¨les)
- [ğŸ“ Structure du Projet](#-structure-du-projet)
- [âš ï¸ Limitations](#ï¸-limitations)
- [ğŸ¤ Contribution](#-contribution)
- [ğŸ“„ License](#-license)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend Web (Vue)                       â”‚
â”‚         HTML5 + CSS3 + Vanilla JavaScript + Chart.js        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP/REST
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI Backend (Async)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  API Routes  â”‚  â”‚   Services   â”‚  â”‚   Schemas    â”‚      â”‚
â”‚  â”‚   (REST)     â”‚â†’ â”‚   (Logic)    â”‚â†’ â”‚  (Pydantic)  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚        â”‚          â”‚          â”‚          â”‚
       â†“        â†“          â†“          â†“          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Reddit  â”‚ â”‚Twitterâ”‚ â”‚AI/ML   â”‚ â”‚PostgreSQLâ”‚ â”‚OpenRouterâ”‚
â”‚  (PRAW)  â”‚ â”‚(Tweepy)â”‚ â”‚Models  â”‚ â”‚(asyncpg) â”‚ â”‚  (LLM)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â†“            â†“            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ RoBERTa  â”‚  â”‚  BART    â”‚  â”‚ CNN      â”‚
    â”‚(Sentiment)â”‚  â”‚(Summary) â”‚  â”‚(Opinion) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ Pipeline de Traitement

1. **Collecte** â†’ Fetching adaptatif multi-plateformes
2. **Filtrage** â†’ OpinionDetector (CNN) + rÃ¨gles heuristiques
3. **Analyse** â†’ RoBERTa sentiments + extraction aspects
4. **Enrichissement** â†’ RÃ©sumÃ©s BART + insights LLM (optionnel)
5. **Persistance** â†’ PostgreSQL + cache mÃ©moire
6. **Visualisation** â†’ Graphiques temps rÃ©el + statistiques

## ğŸ’» Technologies

### Backend Core
- **Framework** : FastAPI 0.104+ (Python 3.9+)
- **API Clients** : 
  - PRAW 7.7+ (Reddit API wrapper)
  - Tweepy 4.16+ (Twitter API v2)
  
### Intelligence Artificielle
- **Transformers** : Hugging Face ğŸ¤—
  - `cardiffnlp/twitter-roberta-base-sentiment-latest` - Analyse sentiments
  - `facebook/bart-large-cnn` - GÃ©nÃ©ration rÃ©sumÃ©s
- **TensorFlow/Keras** : ModÃ¨le CNN custom pour dÃ©tection opinions
- **spaCy 3.7+** : NLP (tokenization, POS tagging)
- **OpenRouter API** : IntÃ©gration LLM (Grok, Claude, GPT-4)

### Base de DonnÃ©es
- **PostgreSQL 14+** : Persistance principale (asyncpg)
- **Cache mÃ©moire** : Fallback automatique si DB indisponible

### Frontend
- **HTML5/CSS3** : Design responsive avec Flexbox/Grid
- **JavaScript ES6+** : Vanilla JS (pas de framework lourd)
- **Chart.js 4.0+** : Visualisations interactives
- **Font Awesome** : IcÃ´nes

### DevOps
- **Docker** : Containerisation
- **Docker Compose** : Orchestration multi-services
- **uvicorn** : Serveur ASGI haute performance

## ğŸš€ Installation Rapide

### PrÃ©requis

- Python 3.9+ 
- PostgreSQL 14+ (ou Docker)
- Git
- 4GB RAM minimum
- ClÃ©s API (voir [Configuration](#ï¸-configuration))

### Installation en 5 Minutes

```bash
# 1. Cloner le repository
git clone https://github.com/votre-username/projet_deep_learning.git
cd projet_deep_learning

# 2. CrÃ©er l'environnement virtuel
python -m venv .venv

# Activer l'environnement
# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate

# 3. Installer les dÃ©pendances
pip install --upgrade pip
pip install -r requirements.txt

# 4. TÃ©lÃ©charger le modÃ¨le spaCy
python -m spacy download en_core_web_sm

# 5. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos clÃ©s API

# 6. DÃ©marrer l'application
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

ğŸ‰ **C'est prÃªt !** Ouvrez http://localhost:8000

### Installation avec Docker (RecommandÃ©)

```bash
# 1. Cloner et configurer
git clone https://github.com/votre-username/projet_deep_learning.git
cd projet_deep_learning
cp .env.example .env
# Ã‰diter .env

# 2. DÃ©marrer tous les services
docker-compose up -d

# 3. VÃ©rifier les logs
docker-compose logs -f app
```

Application disponible sur **http://localhost:8000** ğŸš€

## âš™ï¸ Configuration

### 1ï¸âƒ£ Obtenir les ClÃ©s API

#### Reddit API

1. CrÃ©er un compte sur [Reddit](https://www.reddit.com)
2. Aller sur https://www.reddit.com/prefs/apps
3. Cliquer sur **"create another app..."**
4. Remplir :
   - **Type** : `script`
   - **Name** : `SocialMediaAnalyzer`
   - **Redirect URI** : `http://localhost:8080`
5. Noter le **client_id** (sous le nom) et **client_secret**

#### Twitter API v2

1. CrÃ©er un compte dÃ©veloppeur : [Twitter Developer Portal](https://developer.twitter.com)
2. CrÃ©er un nouveau projet et une application
3. GÃ©nÃ©rer les clÃ©s dans **"Keys and tokens"** :
   - API Key & Secret
   - Bearer Token
   - Access Token & Secret

#### OpenRouter API (Optionnel - pour rÃ©sumÃ©s LLM)

1. CrÃ©er un compte sur [OpenRouter](https://openrouter.ai)
2. Aller sur https://openrouter.ai/keys
3. GÃ©nÃ©rer une clÃ© API
4. Ajouter des crÃ©dits (Ã  partir de $5)

### 2ï¸âƒ£ Fichier .env

CrÃ©er `.env` Ã  la racine :

```env
# =====================================
# API REDDIT
# =====================================
REDDIT_CLIENT_ID=votre_client_id_reddit
REDDIT_CLIENT_SECRET=votre_secret_reddit
REDDIT_USER_AGENT=SocialMediaAnalyzer/1.0

# =====================================
# API TWITTER v2
# =====================================
TWITTER_BEARER_TOKEN=votre_bearer_token
TWITTER_API_KEY=votre_api_key
TWITTER_API_SECRET=votre_api_secret
TWITTER_ACCESS_TOKEN=votre_access_token
TWITTER_ACCESS_TOKEN_SECRET=votre_token_secret

# =====================================
# DATABASE (PostgreSQL)
# =====================================
# Local
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/social_media_analyzer

# Docker
# DATABASE_URL=postgresql+asyncpg://postgres:postgres@db:5432/social_media_analyzer

# =====================================
# LLM CONFIGURATION (OpenRouter)
# =====================================
# Optionnel - pour rÃ©sumÃ©s intelligents avec LLM
OPENROUTER_API_KEY=sk-or-v1-votre-cle-ici
OPENROUTER_MODEL=anthropic/claude-3-sonnet

# ModÃ¨les disponibles :
# - anthropic/claude-3-sonnet (recommandÃ©, ~$0.003 par rÃ©sumÃ©)
# - anthropic/claude-3-opus (meilleur qualitÃ©, ~$0.015 par rÃ©sumÃ©)
# - openai/gpt-4-turbo (~$0.01 par rÃ©sumÃ©)
# - x-ai/grok-beta (si accÃ¨s disponible)

# =====================================
# APPLICATION SETTINGS
# =====================================
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True

# =====================================
# AI MODELS
# =====================================
SENTIMENT_MODEL=cardiffnlp/twitter-roberta-base-sentiment-latest
SUMMARIZATION_MODEL=facebook/bart-large-cnn

# =====================================
# PERFORMANCE
# =====================================
# Nombre max de posts par requÃªte API
MAX_POSTS_PER_REQUEST=30

# Nombre max de commentaires par post
MAX_COMMENTS_PER_POST=10

# Nombre max de posts pour tendances (par plateforme)
MAX_TRENDS_FETCH_PER_PLATFORM=1500

# DÃ©sactiver le zero-shot classifier (plus rapide)
DISABLE_ZERO_SHOT_CLASSIFIER=True
```

### 3ï¸âƒ£ Configuration PostgreSQL

**Avec Docker** : La base est crÃ©Ã©e automatiquement âœ…

**Installation locale** :

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install postgresql postgresql-contrib
sudo systemctl start postgresql

# macOS (Homebrew)
brew install postgresql@14
brew services start postgresql@14

# Windows
# TÃ©lÃ©charger depuis https://www.postgresql.org/download/windows/
```

CrÃ©er la base :

```sql
psql -U postgres
CREATE DATABASE social_media_analyzer;
\q
```

Les tables seront crÃ©Ã©es automatiquement au premier dÃ©marrage ğŸ‰

## ğŸ“– Guide d'Utilisation

### Interface Web

#### 1. Recherche d'Avis

1. **Ouvrir** http://localhost:8000
2. **Entrer un mot-clÃ©** : `iPhone 15`, `Tesla Model 3`, `PlayStation 5`...
3. **SÃ©lectionner plateformes** : Reddit, Twitter ou les deux
4. **Choisir pÃ©riode** : 24h, 7 jours, 30 jours
5. **Cliquer "Analyser les avis"**

#### 2. RÃ©sultats DÃ©taillÃ©s

Vous obtenez :
- ğŸ“Š **Distribution sentiments** : Graphique donut interactif
- ğŸ“ˆ **Comparaison plateformes** : Barres Reddit vs Twitter
- ğŸ“ **Liste des posts** : Titre, texte, auteur, date, upvotes
- ğŸ’¬ **Commentaires** : Sentiments analysÃ©s pour chaque commentaire
- ğŸ·ï¸ **Aspects extraits** : CaractÃ©ristiques clÃ©s mentionnÃ©es

#### 3. Analyse des Tendances

1. **Cliquer "Analyser les tendances"** (aprÃ¨s une recherche)
2. **Visualiser** :
   - Ã‰volution temporelle des mentions (graphique ligne)
   - Distribution des sentiments dans le temps
   - Comparaison Reddit vs Twitter

#### 4. RÃ©sumÃ© LLM Intelligent

1. **Configurer** `OPENROUTER_API_KEY` dans `.env`
2. **Cliquer "RÃ©sumÃ© LLM"** (bouton violet avec ğŸ§ )
3. **Recevoir** un rÃ©sumÃ© intelligent gÃ©nÃ©rÃ© par IA :
   - Satisfaction globale
   - Points nÃ©gatifs principaux
   - Points positifs principaux
   - Conclusion (positif/mitigÃ©/prÃ©occupant)

### Utilisation via API

#### Recherche de Posts

```bash
curl -X POST "http://localhost:8000/api/search" \
  -H "Content-Type: application/json" \
  -d '{
    "keyword": "iPhone 15",
    "platforms": ["reddit", "twitter"],
    "limit": 20,
    "time_filter": "week",
    "include_comments": true
  }'
```

#### Analyse Tendances

```bash
curl -X POST "http://localhost:8000/api/trends" \
  -H "Content-Type: application/json" \
  -d '{
    "keyword": "iPhone 15",
    "platforms": ["reddit"],
    "time_range": "7d"
  }'
```

#### RÃ©sumÃ© LLM

```bash
curl -X GET "http://localhost:8000/api/trends/llm-insight?keyword=iPhone%2015&start_date=2024-12-01&end_date=2024-12-08&platforms=reddit&platforms=twitter"
```

#### Health Check

```bash
curl http://localhost:8000/health
```

### Documentation Interactive

- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc

## ğŸ³ DÃ©ploiement Docker

### Architecture

Le `docker-compose.yml` inclut :
- **app** : Application FastAPI
- **db** : PostgreSQL 14
- **pgadmin** : Interface web PostgreSQL (optionnel)

### Commandes

```bash
# DÃ©marrer
docker-compose up -d

# Logs en temps rÃ©el
docker-compose logs -f app

# ArrÃªter
docker-compose down

# Reconstruire aprÃ¨s modifications
docker-compose up -d --build

# Shell du conteneur
docker-compose exec app bash

# Voir les stats
docker stats
```

### URLs

- Application : http://localhost:8000
- API Docs : http://localhost:8000/docs
- PgAdmin : http://localhost:5050 (admin@admin.com / admin)

## ğŸ“š Documentation API

### Endpoints Principaux

#### `POST /api/search`

Recherche et analyse de posts.

**Request Body** :
```json
{
  "keyword": "iPhone 15",
  "platforms": ["reddit", "twitter"],
  "limit": 30,
  "time_filter": "week",
  "include_comments": true
}
```

**Response** (200 OK) :
```json
{
  "keyword": "iPhone 15",
  "platforms": ["reddit", "twitter"],
  "total_posts": 30,
  "posts": [...],
  "overall_sentiment": {
    "positive": 0.65,
    "negative": 0.15,
    "neutral": 0.20,
    "dominant": "positive"
  },
  "execution_time": 8.5
}
```

#### `POST /api/trends`

Analyse des tendances temporelles.

**Request Body** :
```json
{
  "keyword": "iPhone 15",
  "platforms": ["reddit", "twitter"],
  "time_range": "7d"
}
```

#### `GET /api/trends/llm-insight`

GÃ©nÃ©ration rÃ©sumÃ© intelligent avec LLM.

**Query Parameters** :
- `keyword` : Mot-clÃ© (requis)
- `start_date` : Date ISO format (requis)
- `end_date` : Date ISO format (requis)
- `platforms` : Liste plateformes (optionnel)

#### `GET /health`

VÃ©rification Ã©tat services.

**Response** (200 OK) :
```json
{
  "status": "healthy",
  "timestamp": "2024-12-02T10:00:00Z",
  "services": {
    "reddit": true,
    "twitter": true,
    "sentiment_model": true,
    "opinion_detector": true,
    "database": true,
    "llm_service": false
  }
}
```

### Codes d'Erreur

- `200` : SuccÃ¨s
- `400` : RequÃªte invalide
- `401` : Non autorisÃ©
- `404` : Ressource non trouvÃ©e
- `429` : Rate limit dÃ©passÃ©
- `500` : Erreur serveur interne
- `503` : Service temporairement indisponible

## ğŸ“ Fine-tuning des ModÃ¨les

Le projet inclut un module complet pour amÃ©liorer les performances du modÃ¨le RoBERTa.

### Quick Start

```bash
# 1. VÃ©rifier l'environnement
python -m app.training.setup_training

# 2. Lancer le fine-tuning (30-45 min GPU / 3-5h CPU)
python -m app.training.train_sentiment_roberta

# 3. Tester le modÃ¨le
python -m app.training.test_model
```

### RÃ©sultats Attendus

- **Dataset** : tweet_eval/sentiment (45K+ tweets)
- **AmÃ©lioration** : +3-5% accuracy
- **DurÃ©e** : 30-45 min (GPU) / 3-5h (CPU)
- **ModÃ¨le sauvegardÃ©** : `./models/custom-roberta-sentiment/`

### Utiliser le ModÃ¨le Fine-tunÃ©

Modifier `.env` :
```env
SENTIMENT_MODEL=./models/custom-roberta-sentiment
```

ğŸ“– **Documentation complÃ¨te** : [app/training/README.md](app/training/README.md)

## ğŸ“ Structure du Projet

```
projet_deep_learning/
â”‚
â”œâ”€â”€ ğŸ“ app/                           # Application principale
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                       # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ config.py                     # Configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ api/                       # Couche API
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py                 # Endpoints REST
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ services/                  # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ reddit_service.py         # Collecte Reddit
â”‚   â”‚   â”œâ”€â”€ twitter_service.py        # Collecte Twitter
â”‚   â”‚   â”œâ”€â”€ sentiment_service.py      # Analyse sentiments
â”‚   â”‚   â”œâ”€â”€ trends_service.py         # Analyse tendances
â”‚   â”‚   â”œâ”€â”€ database_service.py       # Persistance PostgreSQL
â”‚   â”‚   â”œâ”€â”€ opinion_detector.py       # CNN dÃ©tection opinions
â”‚   â”‚   â”œâ”€â”€ review_fetcher.py         # Fetching adaptatif
â”‚   â”‚   â”œâ”€â”€ llm_client.py             # Client OpenRouter
â”‚   â”‚   â””â”€â”€ trend_insight_service.py  # GÃ©nÃ©ration insights LLM
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ schemas/                   # SchÃ©mas Pydantic
â”‚   â”‚   â”œâ”€â”€ requests.py
â”‚   â”‚   â””â”€â”€ responses.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ training/                  # Module fine-tuning
â”‚   â”‚   â”œâ”€â”€ train_sentiment_roberta.py
â”‚   â”‚   â”œâ”€â”€ test_model.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ models/                    # ModÃ¨les ML
â”‚       â”œâ”€â”€ opinion_detector_model.h5
â”‚       â””â”€â”€ opinion_tokenizer.pkl
â”‚
â”œâ”€â”€ ğŸ“ frontend/                      # Interface web
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ ğŸ“ css/
â”‚   â”‚   â”œâ”€â”€ style.css
â”‚   â”‚   â””â”€â”€ trends_styles.css
â”‚   â””â”€â”€ ğŸ“ js/
â”‚       â”œâ”€â”€ app.js
â”‚       â””â”€â”€ trends_functions.js
â”‚
â”œâ”€â”€ ğŸ“ tests/                         # Tests unitaires
â”‚   â”œâ”€â”€ conftest.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ .env.example                      # Template variables d'env
â”œâ”€â”€ .gitignore                        # Fichiers ignorÃ©s
â”œâ”€â”€ docker-compose.yml                # Orchestration Docker
â”œâ”€â”€ Dockerfile                        # Image Docker app
â”œâ”€â”€ requirements.txt                  # DÃ©pendances production
â”œâ”€â”€ requirements-dev.txt              # DÃ©pendances dÃ©veloppement
â”œâ”€â”€ LICENSE                           # Licence MIT
â””â”€â”€ README.md                         # Ce fichier
```

## âš ï¸ Limitations

### Limites API

#### Twitter API v2 (Free Tier)
- âœ‹ **500,000 tweets/mois** maximum
- âœ‹ **50 requÃªtes/15 min** (endpoint search)
- âœ‹ **Tweets des 7 derniers jours** uniquement
- ğŸ’¡ **Solution** : Rate limiting automatique

#### Reddit API
- âœ‹ **60 requÃªtes/minute** par IP
- âœ‹ **1000 posts max** par requÃªte
- ğŸ’¡ **Solution** : Pagination intelligente

### Ressources MatÃ©rielles

- **RAM** : 4-8GB minimum
- **Stockage** : ~2GB (modÃ¨les + cache)
- **CPU** : Multi-core recommandÃ©
- **GPU** : Optionnel (accÃ©lÃ¨re fine-tuning 5-10x)
- **Temps traitement** : ~1-2s par post

### PrÃ©cision ModÃ¨les

- **Sentiments** : ~70-75% accuracy
- **Langues** : Anglais principalement
- **Domaines** : OptimisÃ© pour produits tech
- **Sarcasme/ironie** : DÃ©tection limitÃ©e

### ConsidÃ©rations Ã‰thiques

- âœ… Respect ToS Reddit et Twitter
- âœ… Pas de stockage donnÃ©es personnelles
- âœ… Rate limiting strict
- âœ… Anonymisation auteurs
- âš ï¸ Usage acadÃ©mique/recherche recommandÃ©
- âš ï¸ VÃ©rifier conditions commerciales avant production

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! ğŸ‰

### Comment contribuer

1. **Fork** le projet
2. **CrÃ©er une branche** 
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. **Commit** vos changements
   ```bash
   git commit -m 'Add: amazing feature'
   ```
4. **Push** vers la branche
   ```bash
   git push origin feature/AmazingFeature
   ```
5. **Ouvrir une Pull Request**

### Guidelines

- âœ… Suivre **PEP 8**
- âœ… Ajouter **tests**
- âœ… Documenter avec **docstrings**
- âœ… Mettre Ã  jour **README**
- âœ… Tester localement avant PR

### IdÃ©es de Contribution

- ğŸŒ Support multilingue
- ğŸ“Š Nouveaux types de visualisations
- ğŸ¤– Support autres plateformes (YouTube, TikTok...)
- ğŸ§ª Tests end-to-end
- ğŸ“± Application mobile
- ğŸ”’ Authentification utilisateurs

## ğŸ“„ License

DistribuÃ© sous licence **MIT**. Voir `LICENSE` pour plus d'informations.

Ce projet est dÃ©veloppÃ© dans le cadre d'un projet acadÃ©mique Ã  **TEK-UP** - 3Ã¨me cycle (2024-2025).

## ğŸ‘¥ Auteurs

**Projet Deep Learning** - TEK-UP 2024-2025

## ğŸ™ Remerciements

- [Hugging Face ğŸ¤—](https://huggingface.co/) - ModÃ¨les Transformers
- [FastAPI](https://fastapi.tiangolo.com/) - Framework web
- [Chart.js](https://www.chartjs.org/) - Visualisations
- [OpenRouter](https://openrouter.ai/) - AccÃ¨s LLMs
- CommunautÃ©s Reddit et Twitter

## ğŸ“ Support

- ğŸ› **Issues** : [GitHub Issues](https://github.com/votre-username/projet_deep_learning/issues)
- ğŸ’¬ **Discussions** : [GitHub Discussions](https://github.com/votre-username/projet_deep_learning/discussions)
- ğŸ“§ **Email** : votre-email@example.com
- ğŸ“– **Documentation** : Ce README + `/app/training/README.md`

---

<p align="center">
  <b>â­ Si ce projet vous aide, donnez-lui une Ã©toile sur GitHub ! â­</b>
</p>

<p align="center">
  Made with â¤ï¸ by TEK-UP Students
</p>
