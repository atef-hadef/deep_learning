# üöÄ Configuration Groq API

## √âtapes pour configurer Groq

### 1. Cr√©er un compte Groq
1. Visitez [console.groq.com](https://console.groq.com)
2. Cr√©ez un compte gratuit
3. Acc√©dez √† la section "API Keys"

### 2. G√©n√©rer une cl√© API
1. Cliquez sur "Create API Key"
2. Donnez un nom √† votre cl√© (ex: "Social Media Analyzer")
3. Copiez la cl√© g√©n√©r√©e (elle commence par `gsk_...`)

### 3. Configurer le projet
Ouvrez le fichier `.env` et remplacez :
```env
GROQ_API_KEY=your_groq_api_key_here
```

Par votre vraie cl√© API :
```env
GROQ_API_KEY=gsk_votre_cl√©_ici
```

### 4. Mod√®le configur√©
Le mod√®le par d√©faut est **llama-3.3-70b-versatile** :
```env
GROQ_MODEL=llama-3.3-70b-versatile
```

### Mod√®les disponibles sur Groq
- `llama-3.3-70b-versatile` - ‚≠ê Recommand√© (rapide, polyvalent)
- `llama-3.1-70b-versatile` - Alternative stable
- `mixtral-8x7b-32768` - Contexte long (32k tokens)
- `gemma2-9b-it` - L√©ger et rapide

## ‚úÖ V√©rifier la configuration

Lancez le test de v√©rification :
```bash
python test_llm_verification.py
```

Vous devriez voir :
```
‚úÖ Service LLM disponible
‚ÑπÔ∏è  Mod√®le configur√©: llama-3.3-70b-versatile
```

## üéØ Utilisation

Une fois configur√©, le bouton **"R√©sum√© LLM"** dans l'interface utilisera automatiquement Groq pour g√©n√©rer des r√©sum√©s intelligents bas√©s sur les posts affich√©s.

## üìä Limites Groq (Plan gratuit)
- **Vitesse** : Ultra rapide (jusqu'√† 300 tokens/sec)
- **Requ√™tes** : G√©n√©ralement tr√®s g√©n√©reux
- **Mod√®les** : Acc√®s √† plusieurs mod√®les open-source

## üîí S√©curit√©
‚ö†Ô∏è **Ne jamais commiter votre cl√© API dans Git !**
Le fichier `.env` est d√©j√† dans `.gitignore`.

## üí° Avantages de Groq vs OpenRouter
‚úÖ Plus rapide (inf√©rence optimis√©e)
‚úÖ Gratuit avec limites g√©n√©reuses
‚úÖ API compatible OpenAI
‚úÖ Mod√®les open-source (Llama 3.3)
