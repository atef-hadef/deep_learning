"""
üß† TREND INSIGHT SERVICE - LLM-Powered Analysis

Service qui g√©n√®re des insights intelligents sur les tendances
en utilisant un LLM (Grok via OpenRouter)

Author: AI Assistant
Date: December 2025
Version: 1.0
"""

import logging
from typing import List, Dict, Optional
from datetime import datetime
from app.services.llm_client import call_llm, is_llm_available
from app.services.database_service import database_service
from app.services.sentiment_service import sentiment_service
from app.schemas.responses import Post

logger = logging.getLogger(__name__)


async def build_trend_insight(
    keyword: str,
    start_date: str,
    end_date: str,
    platforms: List[str],
    cached_posts: List[Post] = None,
    use_cache_only: bool = False
) -> Dict:
    """
    G√©n√®re un insight intelligent sur les tendances d'un produit/sujet
    en utilisant un LLM (Grok via OpenRouter)
    
    Args:
        keyword: Mot-cl√© recherch√© (ex: "iPhone 15")
        start_date: Date de d√©but au format ISO (ex: "2024-12-01")
        end_date: Date de fin au format ISO (ex: "2024-12-08")
        platforms: Liste des plateformes (["reddit", "twitter"])
        cached_posts: Posts en cache (UNIQUEMENT posts affich√©s avec analyse)
        use_cache_only: Si True, utilise UNIQUEMENT cached_posts (ignore DB)
        
    Returns:
        Dict avec:
        - keyword: Le mot-cl√©
        - start_date, end_date: Les dates
        - platforms: Les plateformes
        - stats: Statistiques num√©riques (total, pct_pos, pct_neu, pct_neg)
        - insight: Texte g√©n√©r√© par le LLM
        - examples_used: Exemples d'avis utilis√©s dans le prompt
        - llm_available: Bool√©en indiquant si le LLM √©tait disponible
    """
    logger.info(
        f"üß† [TrendInsight] Building insight for '{keyword}' "
        f"from {start_date} to {end_date} on {platforms}"
    )

    # 1) V√©rifier disponibilit√© du LLM
    if not is_llm_available():
        logger.warning("‚ö†Ô∏è LLM service not available - returning stats only")
        return {
            "keyword": keyword,
            "start_date": start_date,
            "end_date": end_date,
            "platforms": platforms,
            "stats": {},
            "insight": "Service LLM non disponible. Veuillez configurer OPENROUTER_API_KEY.",
            "examples_used": [],
            "llm_available": False
        }

    # 2) R√©cup√©rer les posts depuis le cache (posts affich√©s) ou base de donn√©es
    start_dt = datetime.fromisoformat(start_date)
    end_dt = datetime.fromisoformat(end_date)
    
    posts = []
    
    # ‚ö†Ô∏è Si use_cache_only=True, utiliser UNIQUEMENT le cache (posts affich√©s)
    if use_cache_only:
        if cached_posts:
            posts = cached_posts
            logger.info(f"üéØ Using {len(posts)} CACHED ANALYZED posts (displayed in UI) for LLM")
        else:
            logger.warning("‚ö†Ô∏è use_cache_only=True but no cached_posts provided")
            return {
                "keyword": keyword,
                "start_date": start_date,
                "end_date": end_date,
                "platforms": platforms,
                "stats": {},
                "insight": "Aucun post en cache. Veuillez effectuer une recherche d'abord.",
                "examples_used": {"positive": [], "negative": []},
                "llm_available": False
            }
    # Sinon, essayer PostgreSQL d'abord
    elif await database_service.is_available():
        logger.info(f"üìä Fetching posts from PostgreSQL database...")
        posts = await database_service.get_posts_by_keyword_and_date(
            keyword=keyword,
            start_date=start_dt,
            end_date=end_dt,
            platforms=platforms
        )
        logger.info(f"üìä Found {len(posts)} posts in PostgreSQL")
    
    # Fallback: utiliser les posts en cache si disponibles
    if not posts and cached_posts:
        logger.info(f"üíæ PostgreSQL unavailable, using {len(cached_posts)} cached posts")
        posts = cached_posts
    
    if not posts:
        logger.warning(f"‚ö†Ô∏è No posts found in database or cache for keyword '{keyword}'")
        return {
            "keyword": keyword,
            "start_date": start_date,
            "end_date": end_date,
            "platforms": platforms,
            "stats": {
                "total": 0,
                "pct_pos": 0,
                "pct_neu": 0,
                "pct_neg": 0
            },
            "insight": f"Aucun avis trouv√© pour g√©n√©rer un r√©sum√©. Veuillez d'abord effectuer une recherche avec le bouton 'Analyser les avis'.",
            "examples_used": [],
            "llm_available": True
        }
    
    logger.info(f"‚úÖ Found {len(posts)} posts in database")

    # 3) Compl√©ter les sentiments manquants
    posts_without_sentiment = [p for p in posts if not p.sentiment]
    if posts_without_sentiment:
        logger.info(f"üß† Computing sentiments for {len(posts_without_sentiment)} posts...")
        texts = [p.text for p in posts_without_sentiment]
        sentiments = await sentiment_service.analyze_batch_sentiments(texts)
        for post, sent in zip(posts_without_sentiment, sentiments):
            post.sentiment = sent

    # 4) Calculer les statistiques
    total = len(posts)
    positive = sum(1 for p in posts if p.sentiment and p.sentiment.dominant == "positive")
    neutral = sum(1 for p in posts if p.sentiment and p.sentiment.dominant == "neutral")
    negative = sum(1 for p in posts if p.sentiment and p.sentiment.dominant == "negative")
    
    pct_pos = (positive / total * 100) if total > 0 else 0
    pct_neu = (neutral / total * 100) if total > 0 else 0
    pct_neg = (negative / total * 100) if total > 0 else 0

    stats = {
        "total": total,
        "positive": positive,
        "neutral": neutral,
        "negative": negative,
        "pct_pos": round(pct_pos, 1),
        "pct_neu": round(pct_neu, 1),
        "pct_neg": round(pct_neg, 1)
    }

    logger.info(
        f"üìä Stats: {total} posts | "
        f"Positifs: {positive} ({pct_pos:.1f}%) | "
        f"Neutres: {neutral} ({pct_neu:.1f}%) | "
        f"N√©gatifs: {negative} ({pct_neg:.1f}%)"
    )

    # 5) Extraire des exemples pour enrichir le prompt
    positive_examples = [
        p.text for p in posts 
        if p.sentiment and p.sentiment.dominant == "positive"
    ][:5]  # Max 5 exemples positifs
    
    negative_examples = [
        p.text for p in posts 
        if p.sentiment and p.sentiment.dominant == "negative"
    ][:5]  # Max 5 exemples n√©gatifs

    examples_used = {
        "positive": positive_examples,
        "negative": negative_examples
    }

    # 6) Construire le prompt pour le LLM
    system_message = {
        "role": "system",
        "content": (
            "Tu es un data analyst expert en analyse de sentiments sur les r√©seaux sociaux. "
            "Ta mission est d'expliquer les r√©sultats d'analyse de mani√®re claire, professionnelle "
            "et concise en fran√ßais. Tu dois fournir des insights actionnables bas√©s sur les donn√©es."
        )
    }

    # Construire la liste des exemples n√©gatifs
    negative_bullets = "\n".join(
        f"  - \"{ex[:150]}...\"" if len(ex) > 150 else f"  - \"{ex}\""
        for ex in negative_examples
    ) if negative_examples else "  - (aucun avis n√©gatif trouv√©)"

    # Construire la liste des exemples positifs
    positive_bullets = "\n".join(
        f"  - \"{ex[:150]}...\"" if len(ex) > 150 else f"  - \"{ex}\""
        for ex in positive_examples
    ) if positive_examples else "  - (aucun avis positif trouv√©)"

    user_message = {
        "role": "user",
        "content": f"""Analyse les donn√©es de sentiment suivantes :

**Sujet** : {keyword}
**P√©riode** : {start_date} ‚Üí {end_date}
**Plateformes** : {', '.join(platforms)}

**Statistiques** :
- Nombre total d'avis analys√©s : {total}
- Avis positifs : {positive} ({pct_pos:.1f}%)
- Avis neutres : {neutral} ({pct_neu:.1f}%)
- Avis n√©gatifs : {negative} ({pct_neg:.1f}%)

**Exemples d'avis n√©gatifs** :
{negative_bullets}

**Exemples d'avis positifs** :
{positive_bullets}

**Instruction** :
√âcris un r√©sum√© en fran√ßais de 5 √† 8 lignes maximum qui :
1. D√©crit la satisfaction globale des utilisateurs
2. R√©sume les principaux points n√©gatifs √©voqu√©s
3. R√©sume les principaux points positifs √©voqu√©s
4. Conclut si la situation est globalement positive, mitig√©e ou pr√©occupante

Sois direct, concis et professionnel. Ne r√©p√®te pas les chiffres d√©j√† affich√©s.
"""
    }

    # 7) Appeler le LLM
    logger.info("ü§ñ Calling LLM to generate insight...")
    try:
        insight_text = await call_llm(
            messages=[system_message, user_message],
            temperature=0.4,  # Assez d√©terministe pour rester factuel
            max_tokens=400    # ~5-8 lignes de texte
        )
        logger.info(f"‚úÖ LLM insight generated: {len(insight_text)} chars")
    except Exception as e:
        logger.error(f"‚ùå Error calling LLM: {e}")
        insight_text = f"Erreur lors de la g√©n√©ration du r√©sum√© LLM : {str(e)}"

    # 8) Retourner le r√©sultat complet
    return {
        "keyword": keyword,
        "start_date": start_date,
        "end_date": end_date,
        "platforms": platforms,
        "stats": stats,
        "insight": insight_text,
        "examples_used": examples_used,
        "llm_available": True
    }
